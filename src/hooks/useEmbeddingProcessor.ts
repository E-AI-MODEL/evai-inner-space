
import { useOptimizedEmbeddings } from './useOptimizedEmbeddings';

export function useEmbeddingProcessor() {
  const { storeOptimizedEmbedding, storeConversationEmbeddingOptimized, searchSimilar } = useOptimizedEmbeddings();

  const storeInputEmbedding = async (
    input: string,
    vectorApiKey: string,
    context: {
      userId?: string;
      conversationId?: string;
    }
  ): Promise<void> => {
    try {
      console.log('üíæ Storing optimized input embedding...');
      console.log(`üìù Input length: ${input.length} chars`);
      
      const wasStored = await storeOptimizedEmbedding(input, vectorApiKey, context);
      
      if (wasStored) {
        console.log('‚úÖ Optimized input embedding stored successfully');
      } else {
        console.log('‚è≠Ô∏è Input embedding skipped due to optimization rules');
      }
    } catch (embeddingError) {
      console.error('‚ö†Ô∏è Failed to store optimized input embedding:', embeddingError);
    }
  };

  const performNeuralSearch = async (
    input: string,
    vectorApiKey: string
  ): Promise<any[]> => {
    console.log('üß† Performing enhanced neural similarity search...');
    console.log(`üîç Search query: "${input.substring(0, 100)}${input.length > 100 ? '...' : ''}"`);
    
    let similarities = [];
    
    try {
      if (!vectorApiKey?.trim()) {
        console.warn('‚ö†Ô∏è No vector API key provided for neural search');
        return [];
      }

      if (!input || input.trim().length < 3) {
        console.warn('‚ö†Ô∏è Input too short for meaningful neural search');
        return [];
      }
      
      // Enhanced search with better parameters
      similarities = await searchSimilar(input, vectorApiKey, 0.5, 10); // Lower threshold, more results
      
      console.log(`üéØ Neural search results: ${similarities.length} matches found`);
      
      if (similarities.length > 0) {
        console.log('üîç Top neural matches:', similarities.slice(0, 3).map(sim => ({
          type: sim.content_type,
          similarity: sim.similarity_score?.toFixed(3) || 'N/A',
          preview: sim.content_text?.substring(0, 50) || 'No content'
        })));
      } else {
        console.log('üîç No neural matches found - this may indicate:');
        console.log('  ‚Ä¢ Limited embedding data in database');
        console.log('  ‚Ä¢ Search threshold too high');
        console.log('  ‚Ä¢ Input doesn\'t match existing content patterns');
      }
      
    } catch (neuralError) {
      console.error('‚ùå Neural search failed:', neuralError);
      console.error('üîß Neural search error details:', {
        errorMessage: neuralError.message,
        hasApiKey: !!vectorApiKey,
        inputLength: input.length
      });
    }
    
    return similarities || [];
  };

  const storeConversationEmbedding = async (
    messages: any[],
    vectorApiKey: string,
    conversationId: string
  ): Promise<void> => {
    try {
      console.log('üíæ Storing optimized conversation embedding...');
      console.log(`üí¨ Messages to process: ${messages.length}`);
      
      if (!messages || messages.length === 0) {
        console.log('‚è≠Ô∏è No messages to store');
        return;
      }
      
      const wasStored = await storeConversationEmbeddingOptimized(
        messages,
        vectorApiKey,
        conversationId
      );
      
      if (wasStored) {
        console.log('‚úÖ Optimized conversation embedding stored successfully');
      } else {
        console.log('‚è≠Ô∏è Conversation embedding skipped due to optimization rules');
      }
    } catch (error) {
      console.error('‚ö†Ô∏è Failed to store optimized conversation embedding:', error);
    }
  };

  return {
    storeInputEmbedding,
    performNeuralSearch,
    storeConversationEmbedding
  };
}
